# SIGIR-2025-Submission-2117
SIGIR-2025-Submission-2117

SIGIR-2025-Submission-2117 ğŸ”
Show Image
Show Image
Query Performance Prediction Pipeline
This repository contains scripts for evaluating search queries using BM25 ranking and training Query Performance Prediction (QPP) models. The pipeline integrates both traditional text-based features and EEG signals for advanced query performance prediction.

ğŸ“‹ Pipeline Overview

BM25 QPP Evaluation: Generate retrieval metrics for queries
QPP Model Training: Train models using the generated metrics


ğŸš€ Getting Started
Requirements
bashCopypip install -r requirements.txt
Step 1: BM25 QPP Evaluation
Generate retrieval metrics for your queries using the BM25 evaluation script:
bashCopypython BM25_QPP_Labels.py --input /path/to/your/dataset.pkl --k 10
Arguments
ArgumentDescriptionRequired--input, -iPath to input dataset pickle fileâœ…--k, -kNumber of top documents to consider (default: 10)âŒ--debug, -dEnable debug outputâŒ--output, -oCustom output path for resultsâŒ
Step 2: Training QPP Models
Train the QPP models using the generated retrieval metrics:
bashCopypython run_machine_learning_models.py --dataset /path/to/evaluation_results.pkl --results-dir /path/to/output_directory
Arguments
ArgumentDescriptionRequiredDefault--dataset, -dPath to evaluation dataset fileâœ…---results-dir, -rDirectory for saving resultsâœ…---metricMetric to use ('ndcg@10' or 'mrr@10')âŒndcg@10--eegInclude EEG featuresâŒFalse--textInclude text featuresâŒFalse--modelModel type (RandomForestRegressor/LGBMRegressor)âŒRandomForestRegressor--loaderData loader to useâŒload_eeg_averaged_across_subjects--evaluatorEvaluator to useâŒgroup_kfold_evaluator

ğŸ“ Example Usage
bashCopy# Step 1: Generate retrieval metrics
python BM25_QPP_Labels.py --input data/my_dataset.pkl --k 10

# Step 2: Train QPP model with both EEG and text features
python run_machine_learning_models.py \
    --dataset data/my_dataset_evaluation_k10.pkl \
    --results-dir results/ \
    --eeg \
    --text \
    --model LGBMRegressor
ğŸ“Š Output

BM25 evaluation results will be saved as a pickle file with the suffix _evaluation_k{k}.pkl
ML model results will be saved in the specified results directory as JSON files


ğŸ“¬ Contact
For questions about the code, please open an issue in this repository.

ğŸ“„ License
This project is licensed under the MIT License - see the LICENSE file for details.
